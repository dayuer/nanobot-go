// Package router provides LLM-based semantic intent routing.
// It analyzes user messages and routes them to the most appropriate agent.
// Mirrors survival/nanobot/llm_router.py.
package router

import (
	"context"
	"crypto/md5"
	"encoding/json"
	"fmt"
	"log"
	"strings"
	"sync"
	"time"

	"github.com/dayuer/nanobot-go/internal/providers"
)

// RouteResult holds the routing analysis result.
type RouteResult struct {
	Primary  string            `json:"primary"`  // Primary agent ID
	Related  []string          `json:"related"`  // Related agent IDs
	Reason   string            `json:"reason"`   // Routing reason
	Domains  []string          `json:"domains"`  // Involved domains
	SubTasks map[string]string `json:"sub_tasks"` // Focused sub-questions for each related agent
}

// AllAgents returns all involved agents (primary + related, deduplicated).
func (r *RouteResult) AllAgents() []string {
	seen := map[string]bool{r.Primary: true}
	result := []string{r.Primary}
	for _, id := range r.Related {
		if !seen[id] {
			seen[id] = true
			result = append(result, id)
		}
	}
	return result
}

// Role describes an available agent for routing.
type Role struct {
	ID          string `json:"id"`
	Description string `json:"description"`
}

// LLMRouter is the semantic intent router using a lightweight LLM model.
type LLMRouter struct {
	roles       []Role
	validIDs    map[string]bool
	model       string
	provider    providers.LLMProvider
	systemPrompt string

	mu    sync.RWMutex
	cache map[string]cacheEntry
}

type cacheEntry struct {
	result RouteResult
	ts     time.Time
}

const (
	cacheTTL = 60 * time.Second
	cacheMax = 256
)

// routerSystemPrompt is the system prompt template for the router model.
const routerSystemPrompt = `ä½ æ˜¯ä¸€ä¸ªæ¶ˆæ¯è·¯ç”±å™¨ã€‚æ ¹æ®ç”¨æˆ·æ¶ˆæ¯çš„è¯­ä¹‰æ„å›¾ï¼Œåˆ†ææœ€é€‚åˆå›ç­”çš„ä¸“å®¶ï¼Œå¹¶ä¸ºç›¸å…³ä¸“å®¶ç”Ÿæˆèšç„¦å­é—®é¢˜ã€‚

## å¯ç”¨ä¸“å®¶è§’è‰²

%s

## åˆ†æè§„åˆ™
1. åˆ¤æ–­ç”¨æˆ·æ¶ˆæ¯æ¶‰åŠçš„æ‰€æœ‰é¢†åŸŸ
2. é€‰æ‹©æœ€ç´§è¿«/æœ€æ ¸å¿ƒçš„é¢†åŸŸä½œä¸ºä¸»è§’è‰² (primary)
3. åˆ—å‡ºæ‰€æœ‰ç›¸å…³çš„è§’è‰² (related)ï¼ŒæŒ‰ç›¸å…³åº¦æ’åº
4. ä¸ºæ¯ä¸ª related è§’è‰²ç”Ÿæˆä¸€ä¸ªèšç„¦å­é—®é¢˜ (sub_tasks)ï¼Œè®©è¯¥ä¸“å®¶ä»è‡ªå·±çš„è§†è§’ç»™å‡ºç®€è¦å»ºè®®
5. ç”¨ä¸€å¥æç®€ä¸­æ–‡è¯´æ˜è·¯ç”±ç†ç”±

## è¿”å›æ ¼å¼ (ä¸¥æ ¼ JSON)
{"primary":"è§’è‰²ID","related":["è§’è‰²ID1","è§’è‰²ID2"],"sub_tasks":{"è§’è‰²ID1":"èšç„¦å­é—®é¢˜1","è§’è‰²ID2":"èšç„¦å­é—®é¢˜2"},"reason":"ä¸€å¥è¯","domains":["é¢†åŸŸ1","é¢†åŸŸ2"]}

## æ³¨æ„
- é—²èŠã€æ‰“æ‹›å‘¼ã€ä¸ç¡®å®šçš„å†…å®¹: primary è®¾ä¸º general, related ä¸ºç©º, sub_tasks ä¸ºç©º
- related åªæ”¾ç¡®å®ç›¸å…³çš„è§’è‰²ï¼Œä¸è¦å‡‘æ•°
- sub_tasks çš„å­é—®é¢˜è¦å…·ä½“ä¸”èšç„¦è¯¥ä¸“å®¶é¢†åŸŸï¼Œ100å­—ä»¥å†…
- å¦‚æœåªæ¶‰åŠä¸€ä¸ªé¢†åŸŸï¼Œrelated å’Œ sub_tasks å¯ä»¥ä¸ºç©º`

// NewLLMRouter creates a new semantic intent router.
func NewLLMRouter(roles []Role, model string, provider providers.LLMProvider) *LLMRouter {
	// Build roles block
	var rolesBlock strings.Builder
	for _, r := range roles {
		fmt.Fprintf(&rolesBlock, "- **%s**: %s\n", r.ID, r.Description)
	}

	validIDs := make(map[string]bool, len(roles))
	for _, r := range roles {
		validIDs[r.ID] = true
	}

	return &LLMRouter{
		roles:        roles,
		validIDs:     validIDs,
		model:        model,
		provider:     provider,
		systemPrompt: fmt.Sprintf(routerSystemPrompt, rolesBlock.String()),
		cache:        make(map[string]cacheEntry, cacheMax),
	}
}

// RouteMulti analyzes a user message for multi-domain routing.
func (r *LLMRouter) RouteMulti(ctx context.Context, content string) RouteResult {
	content = strings.TrimSpace(content)
	if content == "" {
		return RouteResult{Primary: "general"}
	}

	// Cache lookup
	cacheKey := contentHash(content)
	r.mu.RLock()
	if entry, ok := r.cache[cacheKey]; ok && time.Since(entry.ts) < cacheTTL {
		r.mu.RUnlock()
		log.Printf("  ğŸ§  LLM Router cache hit: %s", entry.result.Primary)
		return entry.result
	}
	r.mu.RUnlock()

	// Call LLM
	result, err := r.callLLM(ctx, content)
	if err != nil {
		log.Printf("  âš ï¸ LLM Router failed: %v", err)
		return RouteResult{Primary: "general"}
	}

	// Validate
	if !r.validIDs[result.Primary] {
		log.Printf("  âš ï¸ LLM Router returned invalid primary: '%s', fallback to general", result.Primary)
		result.Primary = "general"
	}
	validRelated := make([]string, 0, len(result.Related))
	for _, id := range result.Related {
		if r.validIDs[id] {
			validRelated = append(validRelated, id)
		}
	}
	result.Related = validRelated

	// Write cache
	r.mu.Lock()
	if len(r.cache) >= cacheMax {
		// Evict oldest
		var oldestKey string
		var oldestTime time.Time
		for k, v := range r.cache {
			if oldestKey == "" || v.ts.Before(oldestTime) {
				oldestKey = k
				oldestTime = v.ts
			}
		}
		delete(r.cache, oldestKey)
	}
	r.cache[cacheKey] = cacheEntry{result: result, ts: time.Now()}
	r.mu.Unlock()

	log.Printf("  ğŸ§  LLM Router: primary=%s, related=%v, reason=%s",
		result.Primary, result.Related, result.Reason)
	return result
}

// callLLM calls the router-level model for multi-domain classification.
func (r *LLMRouter) callLLM(ctx context.Context, content string) (RouteResult, error) {
	msgs := []providers.Message{
		{Role: "system", Content: r.systemPrompt},
		{Role: "user", Content: content},
	}

	resp, err := r.provider.Chat(ctx, providers.ChatRequest{
		Messages:    msgs,
		Model:       r.model,
		MaxTokens:   300,
		Temperature: 0.1,
	})
	if err != nil {
		return RouteResult{Primary: "general"}, err
	}

	raw := ""
	if resp.Content != nil {
		raw = strings.TrimSpace(*resp.Content)
	}
	if raw == "" {
		return RouteResult{Primary: "general"}, fmt.Errorf("empty response")
	}

	// Clean markdown code blocks
	if strings.HasPrefix(raw, "```") {
		lines := strings.SplitN(raw, "\n", 2)
		if len(lines) > 1 {
			raw = lines[1]
		}
		if idx := strings.LastIndex(raw, "```"); idx >= 0 {
			raw = strings.TrimSpace(raw[:idx])
		}
	}

	var result RouteResult
	if err := json.Unmarshal([]byte(raw), &result); err != nil {
		// Fallback: try as plain text ID
		roleID := strings.ToLower(strings.TrimSpace(raw))
		if r.validIDs[roleID] {
			return RouteResult{Primary: roleID, Reason: "single-id fallback"}, nil
		}
		log.Printf("  âš ï¸ LLM Router parse failed: %.100s", raw)
		return RouteResult{Primary: "general"}, nil
	}

	return result, nil
}

// contentHash returns a short hash of the content for caching.
func contentHash(content string) string {
	text := strings.ToLower(strings.TrimSpace(content))
	if len(text) > 200 {
		text = text[:200]
	}
	h := md5.Sum([]byte(text))
	return fmt.Sprintf("%x", h[:6])
}
